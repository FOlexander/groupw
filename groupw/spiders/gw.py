import scrapy
import psycopg2
from scrapy.exceptions import CloseSpider
import re
import os
import datetime
from dotenv import load_dotenv

load_dotenv()

class GwSpider(scrapy.Spider):
    name = "gw"
    allowed_domains = ["www.group-working.com"]
    start_urls = ["https://www.group-working.com/ru/jobs"]
    base_url = "https://www.group-working.com/ru/job/"

    def __init__(self):
        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        self.conn = psycopg2.connect(
            dbname=os.getenv("DB_NAME"),
            user=os.getenv("DB_USER"),
            password=os.getenv("PASSWORD"),
            host=os.getenv("HOST"),
            port=os.getenv("PORT"),
        )
        self.cursor = self.conn.cursor()
        self.existing_vacancies = self.get_existing_vacancies()

    def get_existing_vacancies(self):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö vac_id –≤ –±–∞–∑–µ."""
        self.cursor.execute("SELECT vac_id FROM vac_form_vacancy WHERE site = %s", ('group-working.com',))
        return {row[0] for row in self.cursor.fetchall()}

    def parse(self, response):
        text = response.text
        html_content = text.replace("‚Äú", '"').replace("‚Äù", '"').replace("\\", "")
        pattern = r'"databaseId":\d+'
        links = re.findall(pattern, html_content)
        current_vacancies = set()
        # link ='https://www.group-working.com/ua/job/3850'
        # yield scrapy.Request(url=link, callback=self.parse_vacancy)


        for link in links:
            current_vacancies.add(link)

            if link not in self.existing_vacancies:
                yield scrapy.Request(url=f'{self.base_url}{link.split(":")[-1]}', callback=self.parse_vacancy)

        # –û–±–Ω–æ–≤–ª—è–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏, –∫–æ—Ç–æ—Ä—ã—Ö –±–æ–ª—å—à–µ –Ω–µ—Ç –Ω–∞ —Å–∞–π—Ç–µ
        inactive_vacancies = self.existing_vacancies - current_vacancies
        if inactive_vacancies:
            print(f"–í–∏–¥–∞–ª–µ–Ω—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó: {inactive_vacancies}")
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—è selected_vacancy_id –≤ NULL
            self.cursor.executemany(
                """
                UPDATE vac_form_jobapplication
                SET selected_vacancy_id = NULL
                WHERE selected_vacancy_id = %s
                """,
                [(vac_id,) for vac_id in inactive_vacancies]
            )
            self.conn.commit()
            # –£–¥–∞–ª—è–µ–º –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏
            self.cursor.executemany(
                "DELETE FROM vac_form_vacancy WHERE site = %s AND vac_id = %s", 
                [('group-working.com', vac_id) for vac_id in inactive_vacancies]
            )
            self.conn.commit()

    def parse_vacancy(self, response):
        # print(response.url)
        # with open("test.html", "w", encoding='utf-8') as f:
        #     f.write(response.text)
        vac_id = response.url.split("/")[-1]
        position = response.css('h1::text').get().split(" ‚Äì ")[0]
        job_category = response.css('.ico__profession + p::text').get()
        country = response.css('.ico__location + p::text').get().split(", ")[0]
        
        salary_list = response.css('.ico__salary + p::text').getall()
        salary = ('').join(salary_list).replace(" ", "")

        date_posted = str(datetime.datetime.now().strftime('%d.%m.%Y'))
        try:
            vaccity = response.css('.ico__location + p::text').get().split(", ")[1]
        except:
            vaccity = ''
        tools = ''
        def extract_info(pattern, text, default=''):
            match = re.search(pattern, text)
            return match.group(1) if match else default

        description_list = response.css('.open__content div > p::text').getall()
        strong_list = response.css('.open__content div > p strong::text').getall()
        description = ''.join(description_list)
        # print(strong_list)
        if not strong_list:
            patterns = {
                "vaccity": r"–ì–æ—Ä–æ–¥:\s*(.*?)[\U0001F300-\U0001FAD6]",
                "docs_need": r"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ:(?:\s*\n)?(.*)",
                "schedule": r"–ì—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã:\s*(.*?)[\U0001F300-\U0001FAD6]",
                "apartment": r"–ñ–∏–ª—å–µ:\s*(.*?)[\U0001F300-\U0001FAD6]",
                "uniform": r"–°–ø–µ—Ü–æ–¥–µ–∂–¥–∞:\s*(.*?)[\U0001F300-\U0001FAD6]",
                "transfer": r"–¢—Ä–∞–Ω—Å—Ñ–µ—Ä –Ω–∞ —Ä–∞–±–æ—Ç—É:\s*(.*?)[\U0001F300-\U0001FAD6]",
                "age": r"–î–ª—è –∫–æ–≥–æ:\s*(.*?)[\U0001F300-\U0001FAD6]",
                "experience": r"–û–ø—ã—Ç:\s*(.*?)[\U0001F300-\U0001FAD6]‚ùóÔ∏è",
                "language": r"–ó–Ω–∞–Ω–∏–µ —è–∑—ã–∫–∞:\s*(.*?)[\U0001F300-\U0001FAD6‚ûï]",
                "duties": r"–û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏:\s*(.*?)[\U0001F300-\U0001FAD6]",
                "payment": r"–û–ø–ª–∞—Ç–∞ —á–∏—Å—Ç—ã–º–∏:\s*(.*?)[\U0001F300-\U0001FAD6]",
            }
        else:
            patterns = {
                "vaccity": r"üåÜ\s*(.*?)[\U0001F300-\U0001FAD6]",
                "docs_need": r"‚ûï(?:\s*\n)?(.*)",
                "schedule": r"üóì\s*(.*?)[\U0001F300-\U0001FAD6]",
                "apartment": r"üèò\s*(.*?)[\U0001F300-\U0001FAD6]",
                "uniform": r"ü¶∫\s*(.*?)[\U0001F300-\U0001FAD6]",
                "transfer": r"üöå\s*(.*?)[\U0001F300-\U0001FAD6]",
                "age": r"üë®‚Äçüîß\s*(.*?)[\U0001F300-\U0001FAD6]",
                "experience": r"üí°\s*(.*?)[\U0001F300-\U0001FAD6]‚ùóÔ∏è",
                "language": r"üìö\s*(.*?)[\U0001F300-\U0001FAD6‚ûï]",
                "duties": r"üîë\s*(.*?)[\U0001F300-\U0001FAD6]",
                "payment": r"üí∂\s*(.*?)[\U0001F300-\U0001FAD6]",
            }


        data = {key: extract_info(pattern, description) for key, pattern in patterns.items()}
        data["site"] = "www.group-working.com"
        # print(data)
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–∑—Ä–∞—Å—Ç–∞ –∏ –ø–æ–ª–∞
        if data["age"]:
            age_numbers = re.findall(r'\d+', data["age"])
            
            if len(age_numbers) == 1 and "–¥–æ" in data["age"]:
                age_numbers = [18, int(age_numbers[0])]
            elif len(age_numbers) == 1 and "–≤—ñ–¥" in data["age"]:
                age_numbers = [int(age_numbers[0]), 55]
            
            data["min_age"] = int(age_numbers[0]) if age_numbers else 18
            data["max_age"] = int(age_numbers[1]) if len(age_numbers) > 1 else 55
            data["sex"] = data["age"].split(" ")[0]
        else:
            data["min_age"], data["max_age"], data["sex"] = 18, 55, ' '
        active = True

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É
        self.cursor.execute(
            """
            INSERT INTO vac_form_vacancy (
                vac_id, position, job_category, country, salary, date_posted, sex, 
                vaccity, docs_need, schedule, apartment, uniform, tools, transfer, age,
                min_age, max_age, experience, language, duties, payment, active, site
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (vac_id) DO UPDATE SET 
                position = EXCLUDED.position,
                job_category = EXCLUDED.job_category,
                country = EXCLUDED.country,
                salary = EXCLUDED.salary,
                date_posted = EXCLUDED.date_posted,
                sex = EXCLUDED.sex,
                vaccity = EXCLUDED.vaccity,
                docs_need = EXCLUDED.docs_need,
                schedule = EXCLUDED.schedule,
                apartment = EXCLUDED.apartment,
                uniform = EXCLUDED.uniform,
                tools = EXCLUDED.tools,
                transfer = EXCLUDED.transfer,
                age = EXCLUDED.min_age,
                min_age = EXCLUDED.min_age,
                max_age = EXCLUDED.max_age,
                experience = EXCLUDED.experience,
                language = EXCLUDED.language,
                duties = EXCLUDED.duties,
                payment = EXCLUDED.payment,
                active = EXCLUDED.active,
                site = EXCLUDED.site
            """,
            (vac_id, position, job_category, country, salary, date_posted, data["sex"], data["vaccity"],
             data["docs_need"], data["schedule"], data["apartment"], data["uniform"], tools, data["transfer"], 
             data["age"], data["min_age"], data["max_age"], data["experience"],
             data["language"], data["duties"], data["payment"], active, data["site"])
        )
        self.conn.commit()

    def closed(self, reason):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã –ø–∞—É–∫–∞."""
        self.cursor.close()
        self.conn.close()


